## ğŸ¥ Video: Module 3 â€” Cross-encoders and ColBERT  
**Instructor:** Zain Hassan  
**Video Duration:** ~8 minutes  
**Source:** [Coursera Video](https://www.coursera.org/learn/retrieval-augmented-generation-rag/lecture/8BPMB/cross-encoders-and-colbert)

---

## ğŸ§  Semantic Search Recap

- Most semantic search systems use a **bi-encoder architecture**:
  - Each document is embedded into a **single vector**.
  - The prompt is also embedded into a **single vector**.
  - Retrieval is done by comparing vector similarity using **ANN algorithms**.

> â€œThe term bi-encoder refers to the fact that the documents and prompt are embedded separately.â€

- Advantage: Documents can be embedded **ahead of time**, speeding up search.

---

## ğŸ¯ 1.  Bi-Encoder Architecture

### ğŸ”¹ Separate Semantic Vectors
- Documents and prompts are embedded **separately** using the same embedding model.
- Each document becomes a **single vector**.
- Each prompt becomes a **single vector**.
- These vectors are compared using **vector similarity**.

> â€œThe term bi-encoder refers to the fact that the documents and prompt are embedded separately.â€


### ğŸ”¹ ANN Search
- A **vector database** uses **Approximate Nearest Neighbor (ANN)** search.
- It rapidly identifies documents whose vectors are **close to the prompt vector**.
- This enables **fast semantic retrieval**.

### ğŸ”¹ Document Vectors Are Pre-Computed
- Document embeddings are created **ahead of time**.
- At query time, only the **prompt** needs to be embedded.
- This makes bi-encoders **highly efficient and scalable**.

---

### ğŸ“Š Visual Diagram Breakdown

#### ğŸ”§ Embedding Model Input
- **Prompt** â†’ embedded into: `[0.5, 0.4, 0.8, 0.3, 2]`
- **Documents** â†’ embedded into:
  - Doc 1: `[1, 0.5, 0.4, 0.3, 2]`
  - Doc 2: `[0.8, 0.4, 0.3, 2, 1]`
  - Doc 3: `[0.5, 0.4, 0.3, 2, 1]`

---

### ğŸ” Retrieval Process
- These vectors are stored in a **vector database**.
- When a prompt is received:
  - Its vector is compared to all document vectors.
  - ANN search returns the **most similar documents**.

---

## âœ… Advantages

| Feature              | Benefit                                |
|----------------------|----------------------------------------|
| Preprocessing        | âœ… Documents embedded ahead of time     |
| Speed                | âœ… Only prompt embedded at query time   |
| Storage              | âœ… One vector per document              |
| Scalability          | âœ… Excellent for large corpora          |
| Simplicity           | âœ… Easy to implement and deploy         |

![alt text](images/bi-encoder.png)

---

## ğŸ¯ 2. Cross-Encoder Architecture

### ğŸ”§ How It Works:
- Concatenates the **prompt + document text**.
- Passes the combined text into a **specialized model**.
- Outputs a **relevance score** (typically between 0 and 1).

### ğŸ§ª Example:
- Prompt: â€œGreat places to eat in New Yorkâ€
- Document: Restaurant review
- Cross-encoder input: `"Prompt + Document"`
- Output: Relevance score (e.g., 0.7)

> â€œThis allows the model to understand deep contextual interactions between the prompt and document.â€

### âœ… Benefits:
- **Highest quality** retrieval results.
- Captures **rich semantic relationships**.

### âš ï¸ Drawbacks:
- **No pre-processing** possible as this technique needs to run on prompt-document pairs (prompt needed first).
- **Terrible scalability**:
  - Must run **billions of prompt-document pairs** at query time.
  - Not feasible for large corpora.

![alt text](<images/cross encoder.png>)

---

## âš–ï¸ 3. Summary of Tradeoffs

| Architecture   | Speed       | Quality     | Storage     | Scalability |
|----------------|-------------|-------------|-------------|-------------|
| Bi-encoder     | âœ… Fast      | âš ï¸ Moderate | âœ… Minimal   | âœ… Excellent |
| Cross-encoder  | âŒ Slow      | âœ… Best     | âŒ None      | âŒ Poor      |

> â€œCross-encoders are too inefficient to use as a default search technique.â€

---

## ğŸ§  4. ColBERT Architecture (Contextualized Late Interaction over BERT)

### ğŸ”§ How It Works:
- Documents are embedded **ahead of time**, like bi-encoders.
- But instead of one vector per document, ColBERT generates:
  - **One vector per token** in the document.
  - Same for the prompt.

### ğŸ§ª Example:
- Document: 1,000 tokens â†’ 1,000 vectors
- Prompt: 10 tokens â†’ 10 vectors
- Result: A **10 Ã— 1,000 grid** of similarity scores.

### ğŸ“Š Scoring:
- For each **prompt token**, find the **most similar document token**.
- Take the **maximum similarity score** per prompt token.
- Sum these scores â†’ final document relevance score.

> â€œThis is known as the max sim score.â€

---

## âœ… Benefits of ColBERT

- Captures **deep token-level interactions**.
- **Much faster** than cross-encoders.
- **More accurate** than bi-encoders.

### âš ï¸ Drawbacks:
- **High storage cost**:
  - Must store **one vector per token**.
  - A 2,000-token document â†’ 2,000 vectors.
- **More compute** than bi-encoders, but still usable in real-time.

---

## ğŸ§ª Use Cases

- ColBERT is ideal for domains needing **precision**:
  - Legal
  - Medical
  - Scientific research

> â€œThe trade-off of increased vector storage may be worth it.â€

![alt text](images/ColBERT.png)
---

## ğŸ¯ Final Takeaway

- **Bi-encoders**: Default for speed and scale.
- **Cross-encoders**: Gold standard for quality, but too slow.
- **ColBERT**: Middle ground â€” near cross-encoder quality with bi-encoder speed.

> â€œJoin me in the next video and letâ€™s see how cross-encoders are integrated into production retrieval systems despite their significant inefficiencies.â€ â€” Zain Hassan